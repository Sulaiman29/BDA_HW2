{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sulaiman29/BDA_HW2/blob/main/Copy_of_BDA2025Spring_HW2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYwLs5joJfJN"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\"><b></b>\n",
        "\n",
        "# <h1><center> <font color='black'>Homework 02</font></center></h1>\n",
        "\n",
        "<h2><center> <font color='black'> Regression & Regularization</font></center></h2>    \n",
        "<h2><center> <font color='black'> MTAT.03.319 - Business Data Analytics</font></center></h2>\n",
        "<h2><center> <font color='black'> University of Tartu - Spring 2025</font></center></h2>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMAvgHx6JfJm"
      },
      "source": [
        "# Homework instructions\n",
        "\n",
        "- Please provide the names and student IDs of the team-members (Maximum 2 person) in the field \"Team mates\" below. If you are not working in a team please insert only your name and student ID.\n",
        "\n",
        "- Please provide code where ever applicable.\n",
        "\n",
        "- The accepted submission format is .ipynb file. Please make sure that the privacy settings for the file is public so we can access your code.\n",
        "\n",
        "- The submission will automatically close on <font color='red'>**30 March at 23:59**</font>, so please make sure to submit before the deadline.\n",
        "\n",
        "- ONLY one of the teammates should submit the homework and in the submission description the other person's Name and Student ID must be entered. We will grade the homework and the marks and feedback is applied for both the team members. So please communicate with your team member about marks and feedback if you are submit the homework.\n",
        "\n",
        "- If a question is not clear, please ask us in Moodle ONLY.\n",
        "\n",
        "- After you have finished solving the Homework, please restart the Kernel and run all the cells to check if there is any persisting issues.\n",
        "\n",
        "- Plagiarism is <font color='red'>**PROHIBITED**</font>. Any form of plagiarism will be dealt according to the university policy (https://ut.ee/en/content/academic-fraud).\n",
        "\n",
        "- <font color='red'>**DO NOT CHANGE THE TEMPLATE**</font>\n",
        "\n",
        "- <font color='red'>**Restart the Kernel and Run all the cells once again after you are done.**</font>\n",
        "This will ensure that all the cells run without error. You will find an option in the top menu bar under Kernel tab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfgmDl7JJfJn"
      },
      "source": [
        "**<h2><font color='red'>Team mates:</font></h2>**\n",
        "\n",
        "\n",
        "<font color='red'>Name: </font>&emsp;   <font color='red'>Student ID: </font>\n",
        "\n",
        "\n",
        "<font color='red'>Name: </font>&emsp;   <font color='red'>Student ID: </font>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQFbVbtpJfJn"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "* In this homework you are going to apply supervised learning: Linear Regression method using Scikit-learn package; Scikit-learn (formerly scikits.learn and also known as sklearn) is a free software machine learning library for the Python programming language. It features various classification, regression and clustering algorithms including support vector machines, random forests, gradient boosting, k-means and DBSCAN, and is designed to interoperate with the Python numerical and scientific libraries NumPy and SciPy [https://en.wikipedia.org/wiki/Scikit-learn].\n",
        "\n",
        "### The homework is divided into four sections and the points are distributed as below:\n",
        "<pre>\n",
        "- Linear Regression    -> 3 points\n",
        "- PCA                  -> 3 points\n",
        "- Overfitting          -> 5 points\n",
        "_________________________________________\n",
        "Total                  -> 11 points\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1wszlIpJfJo"
      },
      "source": [
        "# 1. Regression\n",
        "## 1.1 Linear Regression (2 points)\n",
        "\n",
        "We are going to use the Prices dataset that contains 74 columns. Each column represents a feature of houses for sale. The ```SalePrice``` column  shows their prices."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qidamLnMJfJo",
        "outputId": "7352ee23-2ec4-43bb-f416-b4568429a486"
      },
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv(\"Prices.csv\")\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>MSZoning</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>Street</th>\n",
              "      <th>LotShape</th>\n",
              "      <th>LandContour</th>\n",
              "      <th>Utilities</th>\n",
              "      <th>LotConfig</th>\n",
              "      <th>LandSlope</th>\n",
              "      <th>...</th>\n",
              "      <th>EnclosedPorch</th>\n",
              "      <th>3SsnPorch</th>\n",
              "      <th>ScreenPorch</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>MoSold</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>SaleType</th>\n",
              "      <th>SaleCondition</th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>65.0</td>\n",
              "      <td>8450</td>\n",
              "      <td>Pave</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>208500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20</td>\n",
              "      <td>RL</td>\n",
              "      <td>80.0</td>\n",
              "      <td>9600</td>\n",
              "      <td>Pave</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>FR2</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2007</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>181500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>68.0</td>\n",
              "      <td>11250</td>\n",
              "      <td>Pave</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>223500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>70</td>\n",
              "      <td>RL</td>\n",
              "      <td>60.0</td>\n",
              "      <td>9550</td>\n",
              "      <td>Pave</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Corner</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>...</td>\n",
              "      <td>272</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2006</td>\n",
              "      <td>WD</td>\n",
              "      <td>Abnorml</td>\n",
              "      <td>140000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>84.0</td>\n",
              "      <td>14260</td>\n",
              "      <td>Pave</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>FR2</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>250000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 75 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   MSSubClass MSZoning  LotFrontage  LotArea Street LotShape LandContour  \\\n",
              "0          60       RL         65.0     8450   Pave      Reg         Lvl   \n",
              "1          20       RL         80.0     9600   Pave      Reg         Lvl   \n",
              "2          60       RL         68.0    11250   Pave      IR1         Lvl   \n",
              "3          70       RL         60.0     9550   Pave      IR1         Lvl   \n",
              "4          60       RL         84.0    14260   Pave      IR1         Lvl   \n",
              "\n",
              "  Utilities LotConfig LandSlope  ... EnclosedPorch 3SsnPorch ScreenPorch  \\\n",
              "0    AllPub    Inside       Gtl  ...             0         0           0   \n",
              "1    AllPub       FR2       Gtl  ...             0         0           0   \n",
              "2    AllPub    Inside       Gtl  ...             0         0           0   \n",
              "3    AllPub    Corner       Gtl  ...           272         0           0   \n",
              "4    AllPub       FR2       Gtl  ...             0         0           0   \n",
              "\n",
              "  PoolArea MiscVal  MoSold  YrSold  SaleType  SaleCondition SalePrice  \n",
              "0        0       0       2    2008        WD         Normal    208500  \n",
              "1        0       0       5    2007        WD         Normal    181500  \n",
              "2        0       0       9    2008        WD         Normal    223500  \n",
              "3        0       0       2    2006        WD        Abnorml    140000  \n",
              "4        0       0      12    2008        WD         Normal    250000  \n",
              "\n",
              "[5 rows x 75 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5dxc_JaJfJq"
      },
      "source": [
        "The column names are self-explanatory which indicates features of each house."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xt1Kln3rJfJq"
      },
      "source": [
        "**1.1.1. The target label is```SalePrice``` which means, later we will predict the sale-price based on the given features (columns). But for regression task, it is important to ensure that the data is not skewed. In order to do that, please plot the distribution of ```SalePrice``` column and explain what do you see. (0.35 point)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJbRJKE8JfJq"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UthxdZLyJfJq"
      },
      "source": [
        "**<font color='red'>Answer:</font>**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCEjKtlJJfJr"
      },
      "source": [
        "So, the data seems to be skewed which has to be fixed otherwise it may lead to erronous result.\n",
        "Apart from that, look closely, some columns are not numerical. For those, you have to convert them to numerical value or represent them in a way so that the algorithm can understand the data. One of such way is called, one hot encoding. Along with that, the algorithm cannot deal with NaN or Infinite values. So please address all of these in the preprocessing section.\n",
        "\n",
        "- Preprocess for skewed data\n",
        "- Apply one-hot encoding to categorical data types\n",
        "- Replace negative infinite values with 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1s3u1LLJfJr"
      },
      "source": [
        "**1.1.2. After preprocessing the skewed data, plot ```SalePrice``` column distribution again. (0.15 point)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hl0qQwwdJfJs"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='red'> **Answer:**</font>"
      ],
      "metadata": {
        "id": "MalR-JrqO0yI"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQPBZ0QWJfJs"
      },
      "source": [
        "**1.1.3. Calculate the correlation between price and each feature. Which are the top 3 features that have the highest correlation with  price? Is the correlation positive or negative? Explain what happens with the price when each of those 3 features change (consider only one feature at a time) and others are kept constant. (0.5 point)**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A59X1K5fJfJs"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLYyFSd-JfJt"
      },
      "source": [
        "<font color='red'> **Answer:**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qQzbp4RJfJt"
      },
      "source": [
        "**1.1.4.  Now you have to build a regression model that would be trained on training data and later predict the price on test data. You are free to select features on which you want train the model. The dataset has missing values, so please apply the following methods for dealing with the missing data in the features of your choice:**\n",
        "\n",
        "a) mean imputation\n",
        "\n",
        "b) median imputation\n",
        "\n",
        "c) mode imputation\n",
        "\n",
        "d) dropping missing values\n",
        "\n",
        "**Split dataset into the training (80% of the all rows) and test ( 20% of all rows) set, you can use train_test_split function from scikit-learn. While splitting, set the parameter random_state equal to 2, this will reproduce similar split during grading.**\n",
        "\n",
        "**For each of the case report MAE, RMSE and R<sup>2</sup>. Which method works better ?(2.0 points)**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCaoOjKWJfJt"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "\n",
        "methods = ['mean imputation', 'median imputation', 'mode imputation', 'dropping missing values']\n",
        "#Store the result in the following variables\n",
        "MAE = []\n",
        "RMSE = []\n",
        "R2 = []\n",
        "#TODO\n",
        "\n",
        "\n",
        "#print the metrics\n",
        "i = 0\n",
        "\n",
        "for m in methods:\n",
        "    print(\"Method: \" + m + \"  MAE: \" + str(MAE[i]) + \"  RMSE: \" + str(RMSE[i]) + \"  R2: \" + str(R2[i]))\n",
        "    i+=1\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "di6eU4kRJfJt"
      },
      "source": [
        "<font color='red'> **Answer:**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4mCTiasJfJu"
      },
      "source": [
        "**Please store the best MAE, RMSE, r2_best score in the following variables. We will use these variable to compare ```1.2.7```**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XD8eDSFNJfJv"
      },
      "source": [
        "mae_best = MAE[#TODO]    #best MAE\n",
        "rmse_best = RMSE[#TODO]  #best RMSE\n",
        "r2_best = R2[#TODO]      #best R2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgkUo5YBJfJv"
      },
      "source": [
        "# 1.2 Principal Component Analysis (PCA) (3 points)\n",
        "Our model performs quite good. But there is always room to make it better and simpler. By simpler, we mean the reducing the dimensionality of the dataset so that we can have a simpler linear regression model. <br> <br>If you noticed after one-hot encoding, we have 270 features (columns) but all these features do not hold the same level of information. For example, the first feature may hold 50% of the information required to make the linear regression acheive the performance we already had; the last, (feature number 270) may contribute to only 0.0000001% to the total output. Hence, adding this last variable (actually there could be more) to our linear regression model (read equation) will only increase the complexity of the model; space, time and computational complexity. Therefore, it is wise and desirable to make the model simpler yet performing the best (better).\n",
        "<br> <br>\n",
        "One such way to reduce the dimensionality of the dataset is known as Pricipal Component Analysis. Using this method, we can find out which features contribute the most in our model, therefore, we can wisely select how many we need. We will perform, PCA in this section of the homework. <br><br>\n",
        "\n",
        "*There is another powerful method for dimensionality reduction, named t-SNE. We will use t-sne in future homework. <br><br>*\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gm5DmYT3JfJv"
      },
      "source": [
        "**1.2.1. From ```1.1.4``` keep the best method to deal with missing values and apply PCA to reduce the number of features. (1 point)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zy7hzDhHJfJv"
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "\n",
        "X = #TODO\n",
        "y = #TODO\n",
        "#TODO: initialize pca, pass, whiten=True, svd_solver='randomized', random_state=0\n",
        "\n",
        "\n",
        "#TODO: fit pca\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='red'> **Answer:**</font>"
      ],
      "metadata": {
        "id": "aWby6Ko4PCcV"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-w3klggJfJw"
      },
      "source": [
        "**1.2.2. What percentage of the variance is explained by the first five components? (0.25 point)**"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WlNcmGRdPDjd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQEVP0WjJfJw"
      },
      "source": [
        "<font color='red'> **Answer:**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7ELb09LJfJw"
      },
      "source": [
        "It would be helpful if we could see all of the variance against the number of components, so a plot would give us a better understanding of the situation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3FzebW5JfJ2"
      },
      "source": [
        "**1.2.3. Please plot the result of PCA you built in ```1.2.1```<br>\n",
        "X-axis=Number of Components, Y-axis=Total explained variance and explain the result.(0.5 point)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Irp6UKBbJfJ3"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(10,7))\n",
        "lw=2\n",
        "plt.plot(#TODO, color='k', lw=lw)\n",
        "plt.xlabel('Number of components')\n",
        "plt.ylabel('Total explained variance')\n",
        "\n",
        "plt.xlim(0, 300)\n",
        "plt.yticks(np.arange(0, 1.1, 0.1))\n",
        "\n",
        "plt.axhline(0.9, c='c')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHnlCo-5JfJ3"
      },
      "source": [
        "<font color='red'> **Answer:**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_4PB8XRJfJ4"
      },
      "source": [
        "**1.2.4. Again, from ```1.1.4``` keep the best method to deal with missing values and use PCA to reduce the number of features. But you can use only the number of features that are significant in ```1.1.3```, in this case you have to choose an optimum n_component value based on the PCA plot. Otherwise, you can select all of the features and pass the n_components=37. In all cases, keep random_state for PCA equal to 0. (0.25 points)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5V5J9lkJfJ4"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='red'> **Answer:**</font>"
      ],
      "metadata": {
        "id": "sGf3C80oPFbA"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ii2fvRuJfJ4"
      },
      "source": [
        "**1.2.5. Use the new components derived from PCA to predict the house pricing. Keep the ratio of test and train set to 20/80 and the random_state equal to 0. Report MAE, RMSE and R<sup>2</sup> (0.75 point)** <br>\n",
        "*Hint: Now your training data is different. Please use pca.transform(X) function to create your new training dataset. But make sure you have the fitted pca from ```1.2.4```*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nO8i5zgiJfJ4"
      },
      "source": [
        "pca_X = pca.transform(X)\n",
        "\n",
        "\n",
        "methods = ['mean imputation', 'median imputation', 'mode imputation', 'dropping missing values']\n",
        "MAE = []\n",
        "RMSE = []\n",
        "R2 = []\n",
        "\n",
        "X_train_pca, X_test_pca, y_train_pca, y_test_pca = #TODO\n",
        "\n",
        "regressor = LinearRegression()\n",
        "\n",
        "#TODO: train the regression model\n",
        "\n",
        "y_predicted_pca = #TODO: predict on test dataset\n",
        "\n",
        "mae_pca = #TODO: mean absolute error\n",
        "rmse_pca = #TODO: root mean squared error\n",
        "r2_pca = #TODO: R^2\n",
        "\n",
        "\n",
        "print(\"MAE: \" + str(mae_pca) + \"  RMSE: \" + str(rmse_pca) + \"  R2: \" + str(r2_pca))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='red'> **Answer:**</font>"
      ],
      "metadata": {
        "id": "Z18-EyLXPJkq"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJ8DEaLyJfJ4"
      },
      "source": [
        "**1.2.6 The following cell would calculate the difference between pre-PCA and post-PCA. Please explain the situation based on the differences. (0.25 point)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLFLGYHnJfJ5"
      },
      "source": [
        "print(\"MAE difference after PCA: \", mae_best-mae_pca)\n",
        "print(\"RMSE difference after PCA: \", rmse_best-rmse_pca)\n",
        "print(\"R2 difference after PCA: \", r2_best-r2_pca)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTZCW4GEJfJ5"
      },
      "source": [
        "<font color='red'> **Answer:**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVj81M_uJfJ5"
      },
      "source": [
        "## 1.3 Overfitting (5 points)\n",
        "\n",
        "Now our model is comparatively better than the earlier models. It is less complex yet performs the almost the same. Let's dive a little deeper into the model now. In this section, we will check if the model is overfitting. The concept of overfitting has already been delivered in the lectures. However, if you are interesed in honing it up, please take a look here or anywhere you understand better: https://datascience.foundation/sciencewhitepaper/underfitting-and-overfitting-in-machine-learning\n",
        "<br>\n",
        "But, unfortunately it is difficult to know if a model is overfitting or underfitting. One way to know more about model's performance is cross-validation. Cross-validation is also used in the hyperparameter searching to find the best performing model in a given scenario.  \n",
        "We have a few techniques to prevent overfitting and we will focus on\n",
        "- 1.3.1 Cross-validation\n",
        "    - K-Fold cross-validation: Most common (we would apply this one to see the performance of the Linear regression model)\n",
        "    - Leave One Out (LOO): Takes each row as the validation set for once, and trains the model on the rest n-1 rows. Thus, it trains n number of models.\n",
        "\n",
        "    - Leave P-Out (LPO): Creates possible splits after leaving p samples out. For n rows, there would be (nCp) possibile train-test splits.\n",
        "    - (For classification problems) Stratified K-Fold: Ensures relative class proportion is preserved in each train and validation fold. Important when the class label is imbalanced (e.g. 95% label: 1; 5% label: 0).\n",
        "    \n",
        "    *The last three techniques will be discussed in detail in the 7th Lecture.* <br><br>\n",
        "    \n",
        "- 1.3.2 Regularization\n",
        "    - L1 (Lasso)    \n",
        "    - L2 (Ridge)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgnrzErbJfJ5"
      },
      "source": [
        "**1.3.0. Now we have to check if the trained regression model in ```1.1.4``` is overfitting. Please use R<sup>2</sup> value on train and test result to determine the overfitting. Please explain the result from the perspective of the dataset and the value(0.2 point)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-U9AhTxCJfJ5"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aejhzWfUJfJ6"
      },
      "source": [
        "<font color='red'> **Answer:**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "la1JX3IhJfJ6"
      },
      "source": [
        "**1.3.1 Please apply K-fold=10 fold closs validation on the training dataset of ```1.1.4``` Keep random_state=1, shuffle=True, while performing cross validation, make sure that return_train_score=True.(0.5 point)**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cZsA7alJfJ6"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "\n",
        "cv = KFold(#TODO: pass parameeter)\n",
        "#TODO: create model\n",
        "\n",
        "#TODO: evaluate model using R^2, and MSE as evaluation metrics\n",
        "#While setting MSE metrics, make sure you pass the right keyword\n",
        "\n",
        "\n",
        "# report performance\n",
        "print('R^2: %.3f (%.3f)' % (mean(scores['test_r2']), std(scores['test_r2'])))\n",
        "print('MSE: %.3f (%.3f)' % (mean(scores['test_neg_mean_squared_error']), std(scores['test_neg_mean_squared_error'])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='red'> **Answer:**</font>"
      ],
      "metadata": {
        "id": "oGuHm1lkPPTM"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TALQSL6JJfJ6"
      },
      "source": [
        "**1.3.1.2. Please plot the training and test R<sup>2</sup> value where X-axis=number of folds, Y-axis=R<sup>2</sup> value. Explain the plot, if the model shows overfitting or not.(0.3 point)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6AxRDbsJfJ6"
      },
      "source": [
        "plt.figure(figsize=(16,6))\n",
        "#TODO: plot the trendlines"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qq62bO4LJfJ6"
      },
      "source": [
        "<font color='red'> **Answer:**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRU2r7W0JfJ7"
      },
      "source": [
        "**1.3.2  Please apply L1 (Lasso) regularization with variable alpha parameters and report the corresponding alpha value and R<sup>2</sup> value. Use the training split from ```1.1.4``` (1.5 point)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "JBLdIUk6JfJ7"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import Lasso, Ridge\n",
        "\n",
        "\n",
        "cross_val_scores_lasso = []\n",
        "\n",
        "# List to maintain the different values of alpha\n",
        "alpha = []\n",
        "\n",
        "\n",
        "\n",
        "# Loop to for different alpha value\n",
        "for i in range(1, 9):\n",
        "    #TODO: formulate the lasso model where alpha=i * 0.0001\n",
        "\n",
        "    #TODO: fit the lasso model on whole X, y\n",
        "    #TODO: perform 10 fold cross validation and store the result in score variable\n",
        "    scores = #TODO\n",
        "    avg_cross_val_score = mean(scores)*100\n",
        "\n",
        "    cross_val_scores_lasso.append(avg_cross_val_score)\n",
        "    alpha.append(i * 0.0001)\n",
        "\n",
        "# Loop to print the different values of cross-validation scores\n",
        "for i in range(0, len(alpha)):\n",
        "    print(str(alpha[i])+' : '+str(cross_val_scores_lasso[i]))\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='red'> **Answer:**</font>"
      ],
      "metadata": {
        "id": "AkVH-g4qPRtL"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bfFzmDfJfJ7"
      },
      "source": [
        "**1.3.3. Take the best alpha value from ```1.3.2``` and use it to train a new lasso model and report the  R<sup>2</sup> value on test set. Use the train test split from ```1.1.4```. (0.5 point)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26ebQVQ6JfJ7"
      },
      "source": [
        "# Building and fitting the Lasso Regression Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "lassoModelBest = Lasso(#TODO: pass the best alpha value)\n",
        "\n",
        "#TODO: Fit the model again\n",
        "\n",
        "# Evaluating the Lasso Regression model\n",
        "print(lassoModelBest.score(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='red'> **Answer:**</font>"
      ],
      "metadata": {
        "id": "TKhAN3tbPT3N"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNhJ6cwkJfJ7"
      },
      "source": [
        "**1.3.4.  Please apply L2 (Ridge) regularization with variable alpha parameters and report the corresponding alpha value and R<sup>2</sup> value. Use the training split from ```1.1.4``` (1.5 point)**\n",
        "\n",
        "N.B. The $alpha$ here in the ridge regularization is the same as $lambda$ you saw in the lecture. We did not initiate the variable with $lambda$ because $lambda$ is a reserved keyword in python which is used to create small anonymous functions. A $lambda$ function can take any number of arguments, but can only have one expression.\n",
        "You can read more about it here: https://www.w3schools.com/python/ref_keyword_lambda.asp#:~:text=The%20lambda%20keyword%20is%20used,and%20the%20result%20is%20returned."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQXWz0z4JfJ8"
      },
      "source": [
        "cross_val_scores_ridge = []\n",
        "\n",
        "# List to maintain the different values of alpha\n",
        "alpha = []\n",
        "\n",
        "\n",
        "\n",
        "# Loop to for different alpha value\n",
        "for i in range(1, 9):\n",
        "    #TODO: formulate the ridge model where alpha=i * 0.0001\n",
        "\n",
        "    #TODO: fit the ridge model on whole X, y\n",
        "    #TODO: perform 10 fold cross validation and store the result in score variable\n",
        "    scores = #TODO\n",
        "    avg_cross_val_score = mean(scores)*100\n",
        "\n",
        "    cross_val_scores_ridge.append(avg_cross_val_score)\n",
        "    alpha.append(i * 0.0001)\n",
        "\n",
        "# Loop to print the different values of cross-validation scores\n",
        "for i in range(0, len(alpha)):\n",
        "    print(str(alpha[i])+' : '+str(cross_val_scores_ridge[i]))\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='red'> **Answer:**</font>"
      ],
      "metadata": {
        "id": "NKgwq2qcPVS-"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3k6yZXNJfJ8"
      },
      "source": [
        "**1.3.5. Take the best alpha value from ```1.3.4``` and use it to train a new ridge model and report the  R<sup>2</sup> value on test set. Use the train test split from ```1.1.4```. (0.5 point)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JB_FtNHeJfJ8"
      },
      "source": [
        "# Building and fitting the Ridge Regression Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "ridgeModelBest = Ridge(#TODO: pass the best alpha value)\n",
        "\n",
        "#TODO: Fit the model again\n",
        "\n",
        "# Evaluating the ridge Regression model\n",
        "print(ridgeModelBest.score(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='red'> **Answer:**</font>"
      ],
      "metadata": {
        "id": "2Y5DdlEpPYKL"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-5hoCclJfJ8"
      },
      "source": [
        "## How long did it take you to solve the homework?\n",
        "\n",
        "* Please answer as precisely as you can. It does not affect your points or grade in any way. It is okay, if it took 0.5 hours or 24 hours. The collected information will be used to improve future homeworks.\n",
        "\n",
        "\n",
        "<font color='red'> **Answer:**</font>\n",
        "\n",
        "## What is the level of difficulty for this homework?\n",
        "you can put only number between $0:10$ ($0:$ easy, $10:$ difficult)\n",
        "\n",
        "<font color='red'> **Answer:**</font>\n",
        "\n",
        "## Any other comments regarding this homework?\n",
        "\n",
        "<font color='red'> **Answer:**</font>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2-vocwue0ETz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}